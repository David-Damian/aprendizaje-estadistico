#+TITLE: EST-25134: Aprendizaje Estadistico
#+AUTHOR: Prof. Alfredo Garbuno Iñigo
#+EMAIL:  agarbuno@itam.mx
#+DATE: ~Introducción~
:LATEX_PROPERTIES:
#+OPTIONS: toc:nil date:nil author:nil tasks:nil
#+LANGUAGE: sp
#+LATEX_CLASS: handout
#+LATEX_HEADER: \usepackage[spanish]{babel}
#+LATEX_HEADER: \usepackage[sort,numbers]{natbib}
#+LATEX_HEADER: \usepackage[utf8]{inputenc} 
#+LATEX_HEADER: \usepackage[capitalize]{cleveref}
#+LATEX_HEADER: \decimalpoint
#+LATEX_HEADER:\usepackage{framed}
#+LaTeX_HEADER: \usepackage{listings}
#+LATEX_HEADER: \usepackage{fancyvrb}
#+LATEX_HEADER: \usepackage{xcolor}
#+LaTeX_HEADER: \definecolor{backcolour}{rgb}{.95,0.95,0.92}
#+LaTeX_HEADER: \definecolor{codegray}{rgb}{0.5,0.5,0.5}
#+LaTeX_HEADER: \definecolor{codegreen}{rgb}{0,0.6,0} 
#+LaTeX_HEADER: {}
#+LaTeX_HEADER: {\lstset{language={R},basicstyle={\ttfamily\footnotesize},frame=single,breaklines=true,fancyvrb=true,literate={"}{{\texttt{"}}}1{<-}{{$\bm\leftarrow$}}1{<<-}{{$\bm\twoheadleftarrow$}}1{~}{{$\bm\sim$}}1{<=}{{$\bm\le$}}1{>=}{{$\bm\ge$}}1{!=}{{$\bm\neq$}}1{^}{{$^{\bm\wedge}$}}1{|>}{{$\rhd$}}1,otherkeywords={!=, ~, $, \&, \%/\%, \%*\%, \%\%, <-, <<-, ::, /},extendedchars=false,commentstyle={\ttfamily \itshape\color{codegreen}},stringstyle={\color{red}}}
#+LaTeX_HEADER: {}
#+LATEX_HEADER_EXTRA: \definecolor{shadecolor}{gray}{.95}
#+LATEX_HEADER_EXTRA: \newenvironment{NOTES}{\begin{lrbox}{\mybox}\begin{minipage}{0.95\textwidth}\begin{shaded}}{\end{shaded}\end{minipage}\end{lrbox}\fbox{\usebox{\mybox}}}
#+EXPORT_FILE_NAME: ../docs/00-introduccion.pdf
:END:
#+STARTUP: showall
#+PROPERTY: header-args:R :session intro-aprendizaje :exports both :results output org :tangle ../rscripts/00-introduccion.R :mkdirp yes :dir ../
#+EXCLUDE_TAGS: toc github


#+BEGIN_NOTES
*Profesor*: Alfredo Garbuno Iñigo | Primavera, 2023 | Introducción.\\
*Objetivo*. Dar un panorame de lo que rige los principios del curso de aprendizaje estadístico y diferenciarlo de otras estrategias de modelado predictivo. Sentar la notación base. 
#+END_NOTES


* Contenido                                                             :toc:
:PROPERTIES:
:TOC:      :include all  :ignore this :depth 2
:END:
:CONTENTS:
- [[#introducción][Introducción]]
  - [[#caracteristicas-del-aprendizaje-estadístico][Caracteristicas del Aprendizaje Estadístico]]
  - [[#filosofía-del-curso][Filosofía del curso]]
  - [[#principios][Principios]]
- [[#distinciones-con-respecto-a-aprendizaje-de-máquina-ml][Distinciones con respecto a aprendizaje de máquina (ML)]]
- [[#métodos][Métodos]]
  - [[#tareas-de-predicción][Tareas de predicción]]
- [[#notación][Notación]]
  - [[#tipos-de-características][Tipos de características]]
  - [[#notación-objetivos-y-muestras][Notación: objetivos y muestras]]
- [[#repaso-de-probabilidad][Repaso de probabilidad]]
  - [[#definición-espacio-de-probabilidad][~Definición~ [Espacio de Probabilidad]:]]
  - [[#definición-variable-aleatoria][~Definición~ [Variable aleatoria]:]]
  - [[#definición-función-de-acumulación][~Definición~ [Función de acumulación]:]]
  - [[#definición-función-de-densidad][~Definición~ [Función de densidad]:]]
  - [[#teorema-ley-de-los-grandes-números][~Teorema~ [Ley de los Grandes Números]:]]
  - [[#teorema-límite-central][~Teorema~ [Límite Central]:]]
- [[#control-de-versiones][Control de versiones]]
- [[#r-statistical-programming-language][R statistical programming language]]
- [[#ambiente-de-r][Ambiente de R]]
  - [[#por-qué-utilizamos-el-tidyverse][¿Por qué utilizamos el tidyverse?]]
  - [[#por-qué-utilizamos-tidymodels][¿Por qué utilizamos tidymodels?]]
- [[#código-de-r][Código de R.]]
:END:

* Introducción

Herramientas para ~entender reglas de asociación~. Con el objetivo de ~generar
predicciones acertadas~.  No es ~estadística~. No es ~inferencia causal~.

** Caracteristicas del Aprendizaje Estadístico
#+ATTR_REVEAL: :frag (appear)
- Flexibilidad.
- Procesamiento automático.
- Complejidad (en datos).
- Predicción.

#+BEGIN_NOTES

En aprendizaje estadístico usualmente consideramos menos suposiciones de los
datos en contraste con estadistica; pensamos que el procesamiento es automático;
que los datos son complejos; y que el interés primordial es la *predicción*.

#+END_NOTES

** Filosofía del curso

Es importante entender los modelos, la intuición y fortalezas y debilidades de
los métodos que se utilizan en tareas de aprendizaje ~supervisadas~ y ~no
supervisadas~.

** Principios 

Consideraremos los siguientes, tomados de citep:Kuhn2013.

#+REVEAL: split

-  Muchos métodos de aprendizaje son relevantes para una gran variedad de aplicaciones.

#+BEGIN_NOTES

No encasillar en el ámbito académico o estadístico. Por supuesto hay muchos mas
modelos de los que veremos pero nos concentramos en los que no son de nicho.

#+END_NOTES
#+REVEAL: split

- Aprendizaje estadístico *no* es una colección de cajas negras.  

#+BEGIN_NOTES
Lamentablemente no hay un método que sea exitoso para cualquier tipo de
aplicación. Tenemos que conocer bien nuestras herramientas para saber cuál usar
en qué situación.
#+END_NOTES
#+REVEAL: split

-  Una cosa es entender cómo funciona; otra, implementarlo desde cero.

#+BEGIN_NOTES

No reinventaremos la rueda. En el curso nos concentraremos en las ideas, no en
la implementación.

#+END_NOTES
#+REVEAL: split

\newpage

- Conocimiento de dominio. Obtención de información relevante.

#+BEGIN_NOTES

Espero poder transmitir la necesidad de pensar en la aplicación del modelo. Algo
que no se ve dentro de una formulación matemática. Pero la cual, si no se es
cuidadoso podría tener en consecuencia una herramienta inservible al
mediano/largo plazo.

#+END_NOTES


* Distinciones con respecto a aprendizaje de máquina (ML)

En aprendizaje estadístico nos interesa comprender el proceso que genera los
datos y su representatividad estadística.


* Métodos

Aprendizaje ~supervisado~ y ~aprendizaje no supervisado~.

** Tareas de predicción

- Clasificación
- Regresión 

* Notación 

Denotamos por $x$ una ~variable aleatoria~ y por $\mathbb{P}(\cdot)$ una ~función
de distribución~. Escribimos $x \sim \mathbb{P}$ para denotar que la variable
aleatoria $x$ tiene distribución $\mathbb{P}(\cdot)$. Denotamos por
$\mathbb{E}[\cdot]$ el ~valor esperado~ del argumento con respecto a la
distribución que estamos considerando. Durante el curso seremos explícitos en la
variable aleatoria y usaremos
\begin{align}
\mathbb{E}_x[\cdot] = \int_\mathcal{X} \cdot \, \pi(x) \, \text{d}x\,,
\end{align}
o bien, haremos énfasis en la distribución por medio de lo siguiente
\begin{align}
\mathbb{E}_\pi[\cdot] = \int_\mathcal{X} \cdot \, \pi(x) \, \text{d}x\,,
\end{align}
de acuerdo al contexto. 

#+REVEAL: split
Denotamos por $n$ el ~número de observaciones~; $p$ para el ~número de
características~ de dichas observaciones.  Así que, $x_{ij}$ con $i = 1, \ldots,
n$ y $j = 1, \ldots, p$ será un elemento de nuestras observaciones.


** Tipos de características
:PROPERTIES:
:reveal_background: #00468b
:END:


** Notación: objetivos y muestras

Usualmente tendremos una característica que queremos predecir y la denotamos por $y$ . Consideraremos $y \in \mathbb{R}$ ó $y \in \{0,1\}$  ó $y \in \{1, 2, \ldots, K\}$.

#+REVEAL: split

El conjunto de datos que tenemos ~disponible para entrenar~ modelos lo denotamos por
\begin{align}
\mathcal{D}_n = \{ (x_1, y_1), \ldots (x_n, y_n) \}\,.
\end{align}

#+REVEAL: split

Es ideal considerar que además tenemos datos adicionales para ~hacer pruebas~. A este conjunto lo denotaremos por
\begin{align}
\mathcal{T}_m = \{ (x_1, y_1), \ldots (x_m, y_m) \}\,.
\end{align}

#+REVEAL: split
Posiblemente necesitemos notación mas especializada para hacer distinciones
adicionales o el contexto nos ayude a requerir una notación mas laxa. Esto lo
definiremos sobre la marcha.

* Repaso de probabilidad

Consideraremos como requisitos el contenido de ~Cálculo de Probabilidades II~ y
~Álgebra Lineal~ (o equivalentes). En particular lo que requerimos como base es lo siguiente.

*** *~Definición~ [Espacio de Probabilidad]*:
Un espacio de probabilidad está definido por la terna $(\Omega, \mathcal{X}, \mathbb{P})$:
1. El espacio muestral, $\Omega$ (elementos). 
2. El espacio de eventos medibles, $\mathcal{X}$ (subconjuntos). 
3. La medida de probabilidad, $\mathbb{P}: \mathcal{X} \rightarrow [0, 1]$. 

*** *~Definición~ [Variable aleatoria]*:
Una variable aleatoria es una función $X:
\mathcal{X} \rightarrow \mathbb{R}$ con la propiedad de que las pre-imágenes
bajo $X$ son eventos medibles. Es decir,
\begin{align}
\{w \in \mathcal{X} : X(w) \leq x \} \in \mathcal{X} \qquad \forall x \in \mathbb{R}. 
\end{align}
   
*** *~Definición~ [Función de acumulación]*:
Para toda variable aleatoria $X$ tenemos una función de acumulación
$\mathbb{P}_{_X}: \mathbb{R} \rightarrow [0, 1]$ dada por
\begin{align}
\mathbb{P}_{_X}(x) = \mathbb{P} \big( \{w \in \mathcal{X} : X(w) \leq x\} \big)\,.
\end{align}
Esto usualmente lo escribimos como $\mathbb{P}_{_X}(x) = \mathbb{P}\{X \leq x\}$. 

*** *~Definición~ [Función de densidad]*:
Una variable aleatoria es continua si su función de acumulación es ~absolutamente
continua~ y puede ser expresada por medio de
\begin{align}
\mathbb{P}_{_X} (x) = \int_{- \infty}^x \pi (s) \, \text{d}s\,, 
\end{align}
donde la anti-derivada $\pi:\mathbb{R} \rightarrow [0, \infty)$ se llama la ~función de
densidad~ de la variable aleatoria $X$. 

#+REVEAL: split
Las propiedades generales de las distribuciones de probabilidad se pueden
especificar por medio de su centralidad (localización), su dispersión, su rango
de valores, su simetría y el comportamiento de valores extremos.

#+REVEAL: split
En general esto lo podemos extraer de los momentos
\begin{align}
\mathbb{E}(X^p) = \int_{\mathbb{R}}^{} x^p \, \pi(x) \, \text{d}x\,,
\end{align}
o los momentos centrales. Por ejemplo: media y varianza. 

#+REVEAL: split
Uno de los resultados que espero recuerden bien de sus cursos anteriores es el
de la ~Ley de los Grandes Números~. La cual podemos enunciar como:

*** *~Teorema~ [Ley de los Grandes Números]*:
Sea $X_1, X_2, \ldots$ una colección de variables aleatorias independientes e
idénticamente distribuidas ($\mathsf{iid}$) y sea $\bar X_n$ el promedio de un
subconjunto de $n$.  Si denotamos por $\mu$ el valor promedio de $X_i$
dentro de esa colección, entonces tenemos que
\begin{align}
\bar X_n  \rightarrow \mu \quad (\text{casi seguramente})\,.
\end{align}

*** *~Teorema~ [Límite Central]*:
Sea $X_1, \ldots, X_n$ una colección de $n$ variables aleatorias $\mathsf{iid}$ con $\mathbb{E}[X_i] = \mu$ y $\mathbb{V}[X_i] = \sigma^2 < \infty$. Entonces
\begin{align}
\bar X_n \sim \mathsf{N}\left( \mu, \frac{\sigma^2}{n} \right)\,,
\end{align}
para $n$ suficientemente grande. 



* Control de versiones

Los /softwares/ de ~control de versiones~ nos permiten llevar un registro y
administración de cambios en archivos. Usualmente para proyectos de
programación.

#+REVEAL: split
Ayudan a trabajar colaborativamente en ambientes de equipos de trabajo.

#+REVEAL: split
Aunque no exploraremos /todo/ lo que se puede hacer con ~Git~ y ~GitHub~ lo usaremos
para llevar un control del desarrollo y de entrega de tareas. Usaremos los
principios mas básicos. 

# #+REVEAL: split
# #+DOWNLOADED: screenshot @ 2022-08-15 19:40:19
# #+attr_html: :width 700 :align center
# #+attr_latex: :width .33 \linewidth
# [[file:images/20220815-194019_screenshot.png]]

# #+REVEAL: split
# #+DOWNLOADED: screenshot @ 2022-08-15 19:37:37
# #+attr_html: :width 200 :align center
# #+attr_latex: :width .33 \linewidth
# [[file:images/20220815-193737_screenshot.png]]


* ~R~ statistical programming language

~R~ es un lenguaje de programación orientado a cómputo estadístico y generación de
gráficos estadísticos. Está escrito para interactuar por medio de ejecución de
/scripts/ (archivos de texto con instrucciones) o la consola interactiva. Ver
[[fig-terminal]].

#+DOWNLOADED: screenshot @ 2022-08-15 19:54:14
#+attr_html: :width 1200 :align center
#+name: fig-terminal
#+caption: Dos ventanas, un editor de texto y una consola de ~R~.
[[file:images/20220815-195840_screenshot.png]]

#+REVEAL: split
Es usual utilizar un ambiente de desarrollo para programar e interactuar con el
lenguaje. Para ~R~ el mas común es ~Rstudio~ el cual tiene además algunas
extensiones útiles para el desarrollo de análisis estadístico.  Ver [[fig-ide]]. 

#+DOWNLOADED: screenshot @ 2022-08-15 19:56:38
#+attr_html: :width 1200 :align center
#+name: fig-ide
#+caption: Un ambiente de desarrollo, ~Rstudio~. 
[[file:images/20220815-195638_screenshot.png]]

#+REVEAL: split
~Visual Studio Code~ es una alternativa multi-lenguaje para desarrollar proyectos
de análisis estadístico en ~R~. Ver [[fig-browser]]. 

#+DOWNLOADED: screenshot @ 2022-08-15 20:02:39
#+attr_html: :width 1200 :align center
#+name: fig-browser
#+caption: Un ambiente de desarrollo general, ~Visual Code Studio~. En la imagen se muestra una sesión en un explorador de internet. 
[[file:images/20220815-200239_screenshot.png]]

#+REVEAL: split
Y habemos los que nos /conformamos/ con un buen editor de texto como ambiente de
desarrollo. Ver [[fig-emacs]]. 

#+DOWNLOADED: screenshot @ 2022-08-15 20:09:14
#+attr_html: :width 1200 :align center
#+name: fig-emacs
#+caption: Ambiente de desarrollo basado en ~Emacs~. 
[[file:images/20220815-200914_screenshot.png]]

* Ambiente de ~R~

#+begin_src R :exports none :results none
  ## Setup --------------------------------------------
  library(tidyverse)
  library(patchwork)
  library(scales)

  ## Cambia el default del tamaño de fuente 
  theme_set(theme_linedraw(base_size = 25))

  ## Cambia el número de decimales para mostrar
  options(digits = 4)
  ## Problemas con mi consola en Emacs
  options(pillar.subtle = FALSE)
  options(rlang_backtrace_on_error = "none")
  options(crayon.enabled = FALSE)

  ## Para el tema de ggplot
  sin_lineas <- theme(panel.grid.major = element_blank(),
                      panel.grid.minor = element_blank())
  color.itam  <- c("#00362b","#004a3b", "#00503f", "#006953", "#008367", "#009c7b", "#00b68f", NA)

  sin_leyenda <- theme(legend.position = "none")
  sin_ejes <- theme(axis.ticks = element_blank(), axis.text = element_blank())
#+end_src


#+begin_src R :exports code :results org
  library(tidyverse)   # Herramientas de procesamiento
  library(tidymodels)  # Herramientas de modelado 
  library(ISLR)        # Datos del libro de texto
  library(MASS)        # Datos de Boston
#+end_src

** ¿Por qué utilizamos el ~tidyverse~?

#+DOWNLOADED: screenshot @ 2023-01-09 19:46:09
#+attr_html: :width 1200 :align center
[[file:images/20230109-194609_screenshot.png]]

#+REVEAL: split

#+DOWNLOADED: screenshot @ 2023-01-09 20:08:58
#+attr_html: :width 1200 :align center
[[file:images/20230109-200858_screenshot.png]]


** ¿Por qué utilizamos ~tidymodels~?

#+begin_quote
La búsqueda ~CRAN Task View: Machine Learning & Statistical Learning~:
#+end_quote

abess (core)
ahaz
arules
BART
bartMachine
BayesTree
BDgraph
biglasso
bmrm
Boruta
bst
C50
caret
CORElearn
Cubist
deepnet
DoubleML
e1071 (core)
earth
effects
elasticnet
evclass
evtree
frbs
gamboostLSS
gbm (core)
ggRandomForests
glmnet
glmpath
GMMBoost
gradDescent
grf
grplasso
grpreg
h2o
hda
hdi
hdm
ICEbox
ipred
islasso
joinet
kernlab (core)
klaR
lars
lasso2
LiblineaR
maptree
mboost (core)
mlpack
mlr3
mlr3proba
mpath
naivebayes
ncvreg
nnet (core)
OneR
opusminer
pamr
party
partykit
pdp
penalized
penalizedLDA
picasso
plotmo
quantregForest
randomForest (core)
randomForestSRC
ranger
rattle
Rborist
RcppDL
rdetools
relaxo
rgenoud
RGF
RLT
Rmalschains
rminer
ROCR
RoughSets
rpart (core)
RPMM
RSNNS
RWeka
RXshrink
sda
SIS
splitTools
ssgraph
stabs
SuperLearner
svmpath
tensorflow
tgp
torch
tree
trtf
varSelRF
wsrf
xgboost

bibliographystyle:abbrvnat
bibliography:references.bib


* Código de ~R~.                                                         :github:

[[file:../rscripts/00-introduccion.R][Descarga]] el script de la clase. 



