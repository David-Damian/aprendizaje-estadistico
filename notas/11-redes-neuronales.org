#+TITLE: EST-25134: Aprendizaje Estadístico
#+AUTHOR: Prof. Alfredo Garbuno Iñigo
#+EMAIL:  agarbuno@itam.mx
#+DATE: ~Redes neuronales~
#+STARTUP: showall
:REVEAL_PROPERTIES:
#+LANGUAGE: es
#+OPTIONS: num:nil toc:nil timestamp:nil
#+REVEAL_REVEAL_JS_VERSION: 4
#+REVEAL_THEME: night
#+REVEAL_SLIDE_NUMBER: t
#+REVEAL_HEAD_PREAMBLE: <meta name="description" content="Aprendizaje Estadístico">
#+REVEAL_INIT_OPTIONS: width:1600, height:900, margin:.2
#+REVEAL_EXTRA_CSS: ./mods.css
#+REVEAL_PLUGINS: (notes)
:END:
:LATEX_PROPERTIES:
#+OPTIONS: toc:nil date:nil author:nil tasks:nil
#+LANGUAGE: sp
#+LATEX_CLASS: handout
#+LATEX_HEADER: \usepackage[spanish]{babel}
#+LATEX_HEADER: \usepackage[sort,numbers]{natbib}
#+LATEX_HEADER: \usepackage[utf8]{inputenc} 
#+LATEX_HEADER: \usepackage[capitalize]{cleveref}
#+LATEX_HEADER: \decimalpoint
#+LATEX_HEADER:\usepackage{framed}
#+LaTeX_HEADER: \usepackage{listings}
#+LATEX_HEADER: \usepackage{fancyvrb}
#+LATEX_HEADER: \usepackage{xcolor}
#+LaTeX_HEADER: \definecolor{backcolour}{rgb}{.95,0.95,0.92}
#+LaTeX_HEADER: \definecolor{codegray}{rgb}{0.5,0.5,0.5}
#+LaTeX_HEADER: \definecolor{codegreen}{rgb}{0,0.6,0} 
#+LaTeX_HEADER: {}
#+LaTeX_HEADER: {\lstset{language={R},basicstyle={\ttfamily\footnotesize},frame=single,breaklines=true,fancyvrb=true,literate={"}{{\texttt{"}}}1{<-}{{$\bm\leftarrow$}}1{<<-}{{$\bm\twoheadleftarrow$}}1{~}{{$\bm\sim$}}1{<=}{{$\bm\le$}}1{>=}{{$\bm\ge$}}1{!=}{{$\bm\neq$}}1{^}{{$^{\bm\wedge}$}}1{|>}{{$\rhd$}}1,otherkeywords={!=, ~, $, \&, \%/\%, \%*\%, \%\%, <-, <<-, ::, /},extendedchars=false,commentstyle={\ttfamily \itshape\color{codegreen}},stringstyle={\color{red}}}
#+LaTeX_HEADER: {}
#+LATEX_HEADER_EXTRA: \definecolor{shadecolor}{gray}{.95}
#+LATEX_HEADER_EXTRA: \newenvironment{NOTES}{\begin{lrbox}{\mybox}\begin{minipage}{0.95\textwidth}\begin{shaded}}{\end{shaded}\end{minipage}\end{lrbox}\fbox{\usebox{\mybox}}}
#+EXPORT_FILE_NAME: ../docs/11-redes-neuronales.pdf
:END:
#+PROPERTY: header-args:R :session redes-neuronales :exports both :results output org :tangle ../rscripts/11-redes-neuronales.R :mkdirp yes :dir ../
#+EXCLUDE_TAGS: toc

#+BEGIN_NOTES
*Profesor*: Alfredo Garbuno Iñigo | Primavera, 2022 | Redes Neuronales.\\
*Objetivo*: Que veremos.\\
*Lectura recomendada*: Referencia. /Disclaimer/: Todas las figuras han sido tomadas de citep:James2021. 
#+END_NOTES

#+begin_src R :exports none :results none
  ## Setup --------------------------------------------
  library(tidyverse)
  library(patchwork)
  library(scales)
  ## Cambia el default del tamaño de fuente 
  theme_set(theme_linedraw(base_size = 25))

  ## Cambia el número de decimales para mostrar
  options(digits = 2)

  sin_lineas <- theme(panel.grid.major = element_blank(),
                      panel.grid.minor = element_blank())
  color.itam  <- c("#00362b","#004a3b", "#00503f", "#006953", "#008367", "#009c7b", "#00b68f", NA)

  sin_lineas <- theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
  sin_leyenda <- theme(legend.position = "none")
  sin_ejes <- theme(axis.ticks = element_blank(), axis.text = element_blank())
#+end_src


* Contenido                                                             :toc:
:PROPERTIES:
:TOC:      :include all  :ignore this :depth 3
:END:
:CONTENTS:
- [[#introducción][Introducción]]
- [[#precursor-perceptrón][Precursor: perceptrón]]
  - [[#algoritmo][Algoritmo:]]
  - [[#observaciones][Observaciones]]
- [[#red-neuronal-de-una-capa][Red neuronal de una capa]]
  - [[#detalles][Detalles]]
  - [[#ejemplo-clasificación-multi-clase-mnist][Ejemplo: clasificación multi-clase (MNIST)]]
  - [[#el-modelo][El modelo]]
    - [[#cuántos-parámetros-tiene-este-modelo][¿Cuántos parámetros tiene este modelo?]]
  - [[#la-capa-de-salida][La capa de salida]]
  - [[#detalles][Detalles]]
  - [[#regularización][Regularización]]
- [[#modelos-convolucionales][Modelos convolucionales]]
  - [[#ideas-generales][Ideas generales]]
  - [[#capas--de-convolución][Capas  de convolución]]
  - [[#ejemplo-de-un-filtro][Ejemplo de un filtro]]
  - [[#capas-de-resumen-pooling][Capas de resumen (pooling)]]
  - [[#arquitectura-de-una-cnn][Arquitectura de una CNN]]
  - [[#aplicación-de-cnn][Aplicación de CNN]]
  - [[#comentarios][Comentarios]]
- [[#modelos-recurrentes][Modelos recurrentes]]
- [[#casos-de-uso][Casos de uso]]
- [[#ajuste-y-regularización][Ajuste y regularización]]
- [[#software][Software]]
:END:

* Introducción 

- La primera publicación relacionada es la de citet:Rosenblatt1958. 
- Las redes neuronales se volvieron populares en los 80s (con impacto limitado). 
- A partir de ahí, se vio un auge en otros modelos predictivos.
- A partir de 2010, surge /Deep Learning/ con resultados impresionantes.
- Mejora en poder de cómputo, /software/  y datos.

  #+DOWNLOADED: screenshot @ 2022-05-02 21:06:56
  #+caption: Imagen tomada de citep:Zhang2021c. 
  #+attr_html: :width 700 :align center
  [[file:images/20220502-210656_screenshot.png]]


#+REVEAL: split
- El avance y adopción se debe a diversos investigadores en varios ámbitos de lo que rodea /Deep Learning/.
- Por ejemplo ([[https://en.wikipedia.org/wiki/Timeline_of_machine_learning][time-line de eventos importantes]]):
  - citet:Rumelhart1986: Redescubren la regla de la cadena (~backpropagation~). 
  - Yann LeCun, *Corinna Cortes* y Christopher Burges hacen pública la base de datos de [[http://yann.lecun.com/exdb/mnist/][~MNIST~]] (1998).
  - Un equipo de investigadores liderado por *Fei-Fei Li* publica la base de [[https://www.image-net.org/index.php][~imageNet~]] para concurso (2009).
  - Un equipo de investigadores en [[https://www.deepmind.com/publications/mastering-the-game-of-go-with-deep-neural-networks-tree-search][Google Deepmind]] logra vencer a jugadores profesionales en Go (2016).
- Otros perfiles de gente impresionante haciendo investigación en el área se puede encontrar [[https://learn.g2.com/trends/women-in-ai][aquí]]. 


* Precursor: perceptrón

- Objetivo: resolver el problema de clasificación binaria por medio de separaciones lineales.
- Es decir, poder encontrar una $\omega$ tal que
  \begin{gather}
  \langle \omega, x \rangle \geq 0, \qquad \text{ si } y = 1\,,\\
  \langle \omega, x \rangle < 0, \qquad \text{ si } y = -1\,.
  \end{gather}
- Por lo tanto, lo que queremos es un predictor de la forma
  \begin{align}
  \hat y = \mathsf{signo}(\langle \omega, x \rangle)\,.
  \end{align}

** Algoritmo: 

- Empezamos con $\omega^{(1)} = 0$.
- Para cada iteración $t = 1, \ldots, T$:
  - Buscamos un elemento mal clasificado:
    \begin{align}
    y_i \cdot \langle \omega^{(t)}, x_i \rangle < 0\,,
    \end{align}
    dentro de observaciones. 
  - Actualizamos por medio de:
    \begin{align}
    \omega^{(t + 1)} = \omega^{(t)} + y_i \cdot x_i\,.
    \end{align}

- Nos detenemos cuando todas las observaciones están bien clasificadas. 

** Observaciones

- El perceptrón funciona cuando las clases son separables.
- El perceptrón no convergerá cuando las clases no son separables.
- La pérdida asociada a este algoritmo considera términos individuales
  \begin{align}
  \max[0, - y \langle \omega, x \rangle]\,.
  \end{align}
- La idea que utilizaremos: el perceptrón emite una señal si $\langle \omega, x \rangle \geq 0$,

  ¿qué tal que utilizamos un conjunto de perceptrones y los combinamos linealmente?

* Red neuronal de una capa

Consideramos el modelo predictivo de la forma
\begin{align}
f(X) = \beta_0 + \sum_{k = 1}^{K} \beta_k h_k(X)\,,
\end{align}
donde los términos $h_k$ son ~transformaciones no-lineales~ de ~combinaciones
lineales de los atributos~. Es decir,
\begin{align}
h_k(X) = g\left(\omega_{k0} + \sum_{j = 1}^{p} \omega_{kj} X_j\right)\,,
\end{align}
donde $g(\cdot)$ es una transformación no-lineal de $\mathbb{R}$ a $\mathbb{R}$.

#+REVEAL: split
#+DOWNLOADED: screenshot @ 2022-05-02 20:29:08
#+attr_html: :width 800 :align center 
#+ATTR_LATEX: :width 0.45\textwidth
[[file:images/20220502-203004_screenshot.png]]
 

** Detalles

- En la figura anterior tenemos que $A_k = h_k(X) = g\left(\omega_0 + \sum_{j = 1}^{p} \omega_{kj} X_j\right)$.
- La función $g(\cdot)$ se denomina ~función de activación~.
- Las opciones mas populares son: ~ReLU~ o ~sigmoide~.
- Si no utilizamos funciones de activación no-lineales, entonces el modelo seguiría siendo lineal.
- La salida de las funciones de activación son interpretadas como atributos .
- El modelo se entrena (en regresión) minimizando
  \begin{align}
  \sum_{i = 1}^{n} (y_i - f(x_i))^2\,.
  \end{align}
- La solución aprende representaciones de los atributos que pueden servir para predecir. 

** Ejemplo: clasificación multi-clase (~MNIST~)

Tenemos imágenes de $28 \times 28$ pixeles en escala de grises. Tenemos $60K$
datos de entrenamiento y $10K$ datos de validación. Podemos pensar que cada
imagen es un vector de 784 dimensiones. Las etiquetas son los dígitos del 0 al 9. 

*Objetivo*: Predecir la clase de la imagen basada en los valores de los pixeles. 

#+attr_html: :width 800 :align center 
#+ATTR_LATEX: :width 0.45\textwidth
[[file:images/20220503-085256_screenshot.png]]
 

  
** El modelo

Se utiliza una red neuronal de dos capas. La estructura (arquitectura) es 256 unidades en la primera capa, 128
unidades en la capa intermedia y 10 unidades de salida.

*** ¿Cuántos parámetros tiene este modelo?
:PROPERTIES:
:reveal_background: #00468b
:END:

#+attr_html: :width 800 :align center 
#+ATTR_LATEX: :width 0.45\textwidth
[[file:images/20220502-204955_screenshot.png]]


** La capa de salida

- Denotemos por
  \begin{align}
  Z_m = \beta_{m0} + \sum_{\ell = 1}^{K_2} \beta_{m\ell} A_{\ell}^{(2)}\,,  
  \end{align}
  las $m$ combinaciones lineales de las unidades que salen de la segunda capa.
- Denotamos por $m$ es el número de unidades en la capa de salida.

#+REVEAL: split
- Para obtener /probabilidades/ usamos la función ~softmax~ como función de activación en la última capa
  \begin{align}
  f_m(X) = \mathbb{P}(Y = m | X) = \frac{\exp(Z_m)}{\sum_{\ell = 0}^{9} \exp(Z_\ell)}\,,
  \end{align}
  donde entrenamos el modelo minimizando
  \begin{align}
  -\sum_{i = 1}^{n} \sum_{m = 0}^9 y_{im} \log(f_m(x_i))\,,
  \end{align}
la cual llamamos ~entropía cruzada~.
- $y_{im}$ tomará el valor de 1 en la clase que a la que pertenezca la observación $i$ ésima. Todos los demás valores son 0 (~one-hot encoding~).
  
** Detalles 

- La pérdida de ~entropía relativa~ corresponde a un modelo multinomial de $K$ clases:
  \begin{align}
  \mathbb{P}(y | x) = \prod_{k = 1}^K p_{k}(x)^{y_k}\,,
  \end{align}
- Considerando la función de ~softmax~ entonces la función de pérdida (individual) queda
  \begin{align}
  \ell(y, \hat y) = - \left[ \sum_{k = 1}^{K} y_k \log \left( \frac{\exp(z_k)}{\sum_{j = 1}^{K} \exp (z_j)} \right)\right]\,.
  \end{align}
- La cual se puede simplificar
  \begin{align}
  \ell(y, \hat y ) = - \sum_{k = 1}^{K} y_k z_k + \log \left( \sum_{k=1}^{K} \exp(z_k) \right)\,.
  \end{align}
- Lo cual es muy útil para métodos iterativos de optimización
  \begin{align}
  \frac{\partial \ell}{\partial z_j} = \mathsf{softmax}(z_j) - y_j \,.
  \end{align}
  

** Regularización

- Con tantos parámetros en los modelos resulta indispensable /regularizar/ nuestro problema de entrenamiento.
- Consideremos el problema de clasificar imágenes de perros y gatos.
- Las imágenes son tomadas con nuestras cámaras (12Mp) lo cual se traduce en $12 \times 10^6$ píxeles.
- Un modelo de una capa con mil unidades tiene entonces (apróx.) $36 \times 10^9$ parámetros.
- Según una búsqueda en Google (datos de 2019), tenemos una población de 471M perros y 373M gatos. 
  - Esto es (apróx) $0.844 \times 10^9$ imágenes.
- Necesitaríamos  $36/.844 \approx 42.65$ más datos para tener una relación 1 a 1 de parámetros con datos. 
  
#+REVEAL: split
Los métodos usuales de regularización son (mas adelante veremos detalles de esto):
1. Regularización en coeficientes matrices $W_k$.
2. Regularización /dropout/.

#+REVEAL: split
- Resultados en MNIST son:
  #+DOWNLOADED: screenshot @ 2022-05-02 21:31:45
  #+caption: Resultados de generalización obtenidos por distintos modelos en el conjunto de datos de ~MNIST~, fuente: citep:James2021.
  #+attr_html: :width 700 :align center
  #+ATTR_LATEX: :width 0.65\textwidth
     [[file:images/20220502-213145_screenshot.png]]

- A la fecha, los mejores resultados reportan un error de generalización de menos del $0.5\%$
- El error de personas en este conjunto de datos es de $0.2\%$, 

* Modelos convolucionales


#+DOWNLOADED: screenshot @ 2022-05-03 09:25:18
#+attr_html: :width 700 :align center
#+ATTR_LATEX: :width 0.65\textwidth
[[file:images/20220503-092518_screenshot.png]]


- Historia de éxito para problemas de visión por computadora.

#+REVEAL: split
- La base de ~ImageNet~ está compuesta de mas de 20,000 categorías con imágenes de $256 \times 256$ 
- El conjunto de datos son 14M anotadas utilizando ~Amazon Mechanical Turk~.   
- Cada imagen la podemos pensar como una matriz con tres canales de color $\mathsf{RBG}$.
- Por lo tanto una imagen es un arreglo tridimensional de $256 \times 256 \times 3$ de números de 8 bits.

  #+DOWNLOADED: screenshot @ 2022-05-03 09:31:58
  #+attr_html: :width 700 :align center
  #+ATTR_LATEX: :width 0.45\textwidth
  [[file:images/20220503-093158_screenshot.png]]

** Ideas generales


#+DOWNLOADED: screenshot @ 2022-05-03 09:34:08
#+attr_html: :width 700 :align center
#+ATTR_LATEX: :width 0.45\textwidth
[[file:images/20220503-093408_screenshot.png]]

- Las CNN construyen una imagen de manera jerárquica.
- Primero se ~extraen~ características globales (por medio de filtros) y se combinan para crear ~atributos~ específicos de la imagen.
- La extracción y combinación de atributos se logran con capas de *convolución y /pooling/*, 

** Capas  de convolución


#+DOWNLOADED: screenshot @ 2022-05-03 09:39:27
#+attr_html: :width 700 :align center
#+ATTR_LATEX: :width 0.65\textwidth
[[file:images/20220503-093927_screenshot.png]]

- El filtro es una imagen que representa un patrón en la imagen original.
- El filtro se arrastra a lo largo de la imagen y se registran los /scores/.
- Los /scores/ no son mas que un producto interior.
- Los filtros se aprenden durante el ajuste del modelo.

** Ejemplo de un filtro

#+DOWNLOADED: screenshot @ 2022-05-03 09:43:14
#+attr_html: :width 700 :align center
#+ATTR_LATEX: :width 0.45\textwidth
[[file:images/20220503-094314_screenshot.png]]

- Los filtros resaltan características particulares de la imagen.
- Con los resultados de los filtros se crean /nuevas/ características en capas intermedias.

#+REVEAL: split

#+DOWNLOADED: screenshot @ 2022-05-03 09:47:12
#+attr_html: :width 700 :align center
#+ATTR_LATEX: :width 0.70\textwidth
[[file:images/20220503-094712_screenshot.png]]

** Capas de resumen (/pooling/)

#+DOWNLOADED: screenshot @ 2022-05-03 09:50:47
#+attr_html: :width 700 :align center
#+ATTR_LATEX: :width 0.55\textwidth
[[file:images/20220503-095047_screenshot.png]]

- Las capas de resumen se utilizan para generar representaciones de menor resolución.
- Ayuda a enfocar y mejorar la identificación de atributos.
- Permiten que el clasificador sea ~localmente invariante~.
- Reduce la dimensión de los atributos.


#+REVEAL: split

#+DOWNLOADED: screenshot @ 2022-05-03 09:54:06
#+attr_html: :width 700 :align center
#+ATTR_LATEX: :width 0.70\textwidth
[[file:images/20220503-095406_screenshot.png]]


** Arquitectura de una CNN

#+DOWNLOADED: screenshot @ 2022-05-03 09:56:01
#+attr_html: :width 700 :align center
[[file:images/20220503-095601_screenshot.png]]

- El enfoque es sobre los bloques: capas de convolución o resúmenes.
- Los filtros usualmente son pequeños $3 \times 3$.
- Cada filtro crea un nuevo canal en la capa.
- Por un lado reducimos el tamaño de las representaciones. Por otro,  aumentamos el número de filtros.

** Aplicación de CNN

- El procedimiento de entrenamiento es computacionalmente caro.
- En la práctica, no se tienen los recursos para poder entrenarlos.
- Se ha volcado a una estrategia de compartir los pesos de los modelos entrenados.
- Amazon y otros proveedores están capitalizando en estas ideas (~Amazon Rekognition~). 

#+DOWNLOADED: screenshot @ 2022-05-03 10:01:34
#+caption: Modelos disponibles en ~Keras~. 
#+attr_html: :width 700 :align center
[[file:images/20220503-100134_screenshot.png]]


#+REVEAL: split

Nos permite clasificar imágenes propias en estos modelos. 

#+DOWNLOADED: screenshot @ 2022-05-03 10:06:01
#+attr_html: :width 700 :align center
#+ATTR_LATEX: :width 0.70\textwidth
[[file:images/20220503-100601_screenshot.png]]

** Comentarios

- Los filtros que se aprenden de manera automática corresponden con filtros que los expertos en visión por computadora han utilizado.
- No hay garantía de un aprendizaje en sentido generalizable (inteligencia artificial).

  #+DOWNLOADED: screenshot @ 2022-05-03 10:08:35
  #+attr_html: :width 700 :align center
  [[file:images/20220503-100835_screenshot.png]]

#+REVEAL: split
#+DOWNLOADED: screenshot @ 2022-05-03 10:09:12
#+attr_html: :width 700 :align center
#+ATTR_LATEX: :width 0.50\textwidth
  [[file:images/20220503-100912_screenshot.png]]


#+REVEAL: split
#+DOWNLOADED: screenshot @ 2022-05-03 10:10:17
#+attr_html: :width 700 :align center
  [[file:images/20220503-101017_screenshot.png]]


* Modelos recurrentes

* Casos de uso

* Ajuste y regularización

* /Software/

bibliographystyle:abbrvnat
bibliography:references.bib

