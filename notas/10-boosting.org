#+TITLE: EST-25134: Aprendizaje Estadístico
#+AUTHOR: Prof. Alfredo Garbuno Iñigo
#+EMAIL:  agarbuno@itam.mx
#+DATE: ~Ensambles: Boosting~
#+STARTUP: showall
:LATEX_PROPERTIES:
#+OPTIONS: toc:nil date:nil author:nil tasks:nil
#+LANGUAGE: sp
#+LATEX_CLASS: handout
#+LATEX_HEADER: \usepackage[spanish]{babel}
#+LATEX_HEADER: \usepackage[sort,numbers]{natbib}
#+LATEX_HEADER: \usepackage[utf8]{inputenc} 
#+LATEX_HEADER: \usepackage[capitalize]{cleveref}
#+LATEX_HEADER: \decimalpoint
#+LATEX_HEADER:\usepackage{framed}
#+LaTeX_HEADER: \usepackage{listings}
#+LATEX_HEADER: \usepackage{fancyvrb}
#+LATEX_HEADER: \usepackage{xcolor}
#+LaTeX_HEADER: \definecolor{backcolour}{rgb}{.95,0.95,0.92}
#+LaTeX_HEADER: \definecolor{codegray}{rgb}{0.5,0.5,0.5}
#+LaTeX_HEADER: \definecolor{codegreen}{rgb}{0,0.6,0} 
#+LaTeX_HEADER: {}
#+LaTeX_HEADER: {\lstset{language={R},basicstyle={\ttfamily\footnotesize},frame=single,breaklines=true,fancyvrb=true,literate={"}{{\texttt{"}}}1{<-}{{$\bm\leftarrow$}}1{<<-}{{$\bm\twoheadleftarrow$}}1{~}{{$\bm\sim$}}1{<=}{{$\bm\le$}}1{>=}{{$\bm\ge$}}1{!=}{{$\bm\neq$}}1{^}{{$^{\bm\wedge}$}}1{|>}{{$\rhd$}}1,otherkeywords={!=, ~, $, \&, \%/\%, \%*\%, \%\%, <-, <<-, ::, /},extendedchars=false,commentstyle={\ttfamily \itshape\color{codegreen}},stringstyle={\color{red}}}
#+LaTeX_HEADER: {}
#+LATEX_HEADER_EXTRA: \definecolor{shadecolor}{gray}{.95}
#+LATEX_HEADER_EXTRA: \newenvironment{NOTES}{\begin{lrbox}{\mybox}\begin{minipage}{0.95\textwidth}\begin{shaded}}{\end{shaded}\end{minipage}\end{lrbox}\fbox{\usebox{\mybox}}}
#+EXPORT_FILE_NAME: ../docs/10-boosting.pdf
:END:
#+PROPERTY: header-args:R :session boosting :exports both :results output org :tangle ../rscripts/10-boosting.R :mkdirp yes :dir ../
#+EXCLUDE_TAGS: toc latex

#+BEGIN_NOTES
*Profesor*: Alfredo Garbuno Iñigo | Primavera, 2023 | Ensambles y /Boosting/.\\
*Objetivo*: En esta sección estudiaremos otra estrategia para combinar modelos en uno sólo. La estrategia que estudiaremos en esta sección es un mecanismo altamente flexible para regresión y clasificación y actualmente representa el estado del arte para resolver problemas de predicción con datos tabulares.\\
*Lectura recomendada*: Capítulo 10 del libro citet:Hastie2009c.
#+END_NOTES

#+begin_src R :exports none :results none
  ## Setup ---------------------------------------------------------------------
  library(tidyverse)
  library(patchwork)
  library(scales)

  ## Cambia el default del tamaño de fuente 
  theme_set(theme_linedraw(base_size = 25))

  ## Cambia el número de decimales para mostrar
  options(digits = 4)
  ## Problemas con mi consola en Emacs
  options(pillar.subtle = FALSE)
  options(rlang_backtrace_on_error = "none")
  options(crayon.enabled = FALSE)

  ## Para el tema de ggplot
  sin_lineas <- theme(panel.grid.major = element_blank(),
                      panel.grid.minor = element_blank())
  color.itam  <- c("#00362b","#004a3b", "#00503f", "#006953", "#008367", "#009c7b", "#00b68f", NA)

  sin_leyenda <- theme(legend.position = "none")
  sin_ejes <- theme(axis.ticks = element_blank(), axis.text = element_blank())
#+end_src

* Contenido                                                             :toc:
:PROPERTIES:
:TOC:      :include all  :ignore this :depth 3
:END:
:CONTENTS:
- [[#introducción][Introducción]]
- [[#modelos-aditivos-secuenciales][Modelos aditivos secuenciales]]
  - [[#clasificación-binaria][Clasificación binaria]]
    - [[#para-pensar][Para pensar:]]
- [[#gradient-boosting][Gradient boosting]]
  - [[#pseudo-código-árboles-de-regresión][Pseudo-código (árboles de regresión)]]
  - [[#funciones-de-pérdida][Funciones de pérdida]]
  - [[#parámetros-a-optimizar][Parámetros a optimizar]]
- [[#importancia-de-variables][Importancia de variables]]
:END:

* Introducción

/Boosting/ es otra estrategia de agregación de modelos. Es una herramienta
bastante general que puede ser utilizada para problemas de regresión o
clasificación citep:Schapire2001. La estrategia de ~boosting~ es una ~estrategia
secuencial~ que busca mejorar la capacidad predictiva lograda anteriormente.

#+REVEAL: split
Usualmente con /boosting/ utilizamos árboles pequeños (sesgo alto), al contrario de bosques
aleatorios donde se prefieren árboles profundos (sesgo bajo).

#+REVEAL: split
En /boosting/ el sesgo se disminuye con modelos predictivos que se encargan de
distintos grupos en el conjunto de entrenamiento. La varianza se puede controlar
con el parámetro de tasa de aprendizaje.

* Modelos aditivos secuenciales

En el marco de ~modelos aditivos secuenciales~ aplicados a regresión, consideremos
el contexto de modelado por etapas.  En este marco, consideremos un predictor de
la forma
\begin{align}
f(x) = \sum_{k = 1}^{M} \beta_k \, b_k(x) = \sum_{k=1}^{M} T_k(x)\,,
\end{align}
donde cada término es el resultado de ajustar un árbol de regresión.

#+BEGIN_NOTES
Recuerda que un árbol $T_k$ de decisión está definido por sus parámetros
$\theta_k$ los cuales incluyen las variables que se utilizan para los cortes, el
punto de corte y la predicción en cada una de las regiones terminales.
#+END_NOTES

#+REVEAL: split
Resolver este problema es dificil pues se tienen que ajustar los coeficientes y
los árboles al mismo tiempo. Asi que lo resolveremos de manera secuencial. Es
decir, consideremos que estamos en la iteración $m$ y que un modelo pre-entrenado
\begin{align}
f_{m-1}(x) = \sum_{k = 1}^{m-1} T_k(x)\,,
\end{align}
donde $T_k$ con $k = 1, \ldots, m-1$ son los árboles individualmente entrenados.

\newpage
#+REVEAL: split
Para la iteración actual, ajustaremos un modelo adicional al resolver
\begin{align}
\min_{T \in \mathcal{T}} \sum_{i = 1}^{n} \ell\left( y_i, f_{m-1}(x_i) + T(x_i) \right)\,,
\end{align}
donde $\ell(y, \hat{y})$ es una función de pérdida adecuada.

#+REVEAL: split
En el contexto de regresión, si utilizamos pérdida cuadrática podemos agrupar y reescribir
\begin{align}
\min_{T\in \mathcal{T}} \sum_{i = 1}^{n} \left( r_i^{(m)} - T(x_i) \right)^2\,,
\end{align}
donde $r_i^{(m)}$ es el residual que enfrentamos al momento de ajustar el
$m\text{-ésimo}$ modelo.

** Clasificación binaria

Para problemas de clasificación necesitamos resolver en escala logarítmica para después transformar a probabilidades por medio de
\begin{align}
\mathbb{P}(Y = 1| x) = p(x) = h(f(x))\,,
\end{align}
donde $h$ es la función logística.

#+REVEAL: split
En este caso resolvemos el problema de optimización
\begin{align}
\min_{T\in \mathcal{T}} \sum_{i = 1}^{n} \ell \left( y_i, f_{m-1}(x_i) + T(x_i) \right)\,,
\end{align}
donde $\ell$ es la ~devianza~ ( - 2 $\times$  log-verosimilitud). Además, usaremos la siguiente codificación de las clases $y \in \{-1, 1\}$. Por lo que la devianza la podemos escribir como
\begin{align}
\ell(y, \hat z) = - \left[  ( y + 1) \log h(\hat z) - (y - 1) \log (1 - h(\hat z) )\right] \,,
\end{align}
la cual se puede escribir (utilizando la expresión de la función $h$) como
\begin{align}
\ell(y, \hat z)  = 2 \log \left( 1 + e^{-y \hat z} \right)\,. 
\end{align}

#+BEGIN_NOTES
Nota que en el contexto de regresión el producto $y \hat{z}$ tiene un efecto similar al de un residual en el contexto de regresión. ¿Qué pasa con los signos de la categoría observada $y$ y del /score/ latente $\hat{z}$ cuando coinciden y cuando no?
#+END_NOTES

#+REVEAL: split
Esto nos permite formular el problema de optimización como 
\begin{align}
\min_{T \in \mathcal{T}} \sum_{i = 1}^{n} 2 \log \left( 1 + e^{-y_i \cdot \left(f_{m-1}(x_i) + T(x_i)\right)} \right)\,,
\end{align}
el cual puede ser re-escrito como 
\begin{align}
\min_{T \in \mathcal{T}} \sum_{i = 1}^{n} 2 \log \left( 1 + d_{i}^{(m)} e^{-y_i T(x_i)} \right)\,.
\end{align}

*** Para pensar:
:PROPERTIES:
:reveal_background: #00468b
:END:
¿Cómo cambia la función objetivo si la función de pérdida es una pérdida exponencial? Es decir, bajo
\begin{align}
\ell(y, f_m(x)) = \exp \left(  - y f_m(x)  \right)\,.
\end{align}


#+BEGIN_NOTES
En este caso (clasificación binaria) vemos que la formulación no es tan fácil
que con pérdida cuadrática en el contexto de regresión. Sin embargo, parece ser
que los datos reciben una ponderación $d_i^{(m)}$.
#+END_NOTES

* /Gradient boosting/

Utilizaremos /gradient boosting/ para resolver la formulación anterior. Esta técnica se puede aplicar de manera general para cualquier función de pérdida. Lo que necesitamos es resolver
\begin{align}
\min_{T\in \mathcal{T}} \sum_{i = 1}^{n} \ell\left( y_i, f_{m-1}(x_i) + T(x_i) \right)\,,
\end{align}
donde podemos interpretar como /qué tanto tenemos que movernos a partir de $f_{m-1}$ para disminuir la función de pérdida/.

#+REVEAL: split
Si nos fijamos en uno de los términos y escribimos
\begin{align}
\ell(y_i, f_{m-1}(x_i) + z_i)\,,
\end{align}
entonces sabemos que tenemos que modificar de acuerdo a
\begin{align}
z_i = - \lambda \cdot \frac{\partial \ell}{\partial z_i} \left(  y_i, f_{m-1}(x_i) + z \right) \big|_{z = 0}\,,
\end{align}
donde tomamos una ~longitud de paso~ ($\lambda$) para estabilizar el proceso de optimización.

#+REVEAL: split
La restricción que tenemos es que $z_i = T(x_i)$ para toda observación. De hecho, lo mejor que podríamos tener es que
\begin{align}
T(x_i) \approx \frac{\partial \ell}{\partial z_i} \left(  y_i, f_{m-1}(x_i) \right) = g_{i,m}\,.
\end{align}

#+REVEAL: split
Así que formulamos un nuevo problema de optimización como 
\begin{align}
\min_{T\in \mathcal{T}} \sum_{i = 1}^{n} \left( g_{i,m} - T(x_i) \right)^2\,,
\end{align}
donde $g_{i,m}$ es el gradiente de la función objetivo en la iteración $m$ evaluando en la observación $i$. Por lo que la actualización sería de la forma
\begin{align}
f_m(x) = f_{m-1}(x) + \lambda T(x)\,.
\end{align}

** Pseudo-código (árboles de regresión)

#+BEGIN_NOTES
El caso de regresión con pérdida cuadrática se presenta a continuación como un ejemplo. Nota que en esta formulación el problema de optimización en términos del gradiente de la función de pérdida es equivalente a ajustar los residuales. Esto nos ayuda a conectar la formulación con resolver un problema predictivo. La tasa de aprendizaje en este caso, previene el sobreajuste pues ayuda a reducir la importancia de la solución a los residuales. 
#+END_NOTES


1. Definimos $\hat f(x) = 0$ , y $r_i = y_i$ para toda observación en el conjunto de entrenamiento.
2. Para cada $m = 1, 2, \ldots, {\color{orange} M}$ :
   1. Ajustamos un árbol sencillo $\hat f_{m}$ con ${\color{orange} d}+1$ nodos terminales para el conjunto $\{(x_i, r_i)\}_{i = 1}^n$.
   2. Actualizamos el predictor $\hat f$ al incluir una versión escalada del nuevo árbol
      \begin{align}
      \hat f (x) \leftarrow \hat f(x) + {\color{orange} \lambda} \hat f_{m}(x) \,.
      \end{align}
   3. Actualizamos los residuales 
      \begin{align}
      r_i \leftarrow r_i - {\color{orange} \lambda} \hat f_{m}(x) \,.
      \end{align}
3. Regresamos el modelo
   \begin{align}
   \hat f(x) = \lambda \sum_{m = 1}^{M} \hat f_{m}(x) \,.
   \end{align}

** Funciones de pérdida

La selección de función de pérdida parte crucial del algoritmo y se escoge de acuerdo al problema y al objetivo que se quiera resolver. Por ejemplo, en regresión tenemos (por nombrar un par):
1. *Pérdida cuadrática*:
   \begin{align}
   \ell(y, z) = \frac12 (y - z)^2, \qquad \frac{\partial \ell}{\partial z} = - (y - z)\,.
   \end{align}
2. *Pérdida absoluta*: 
   \begin{align}
   \ell(y, z) = |y - z|, \qquad \frac{\partial \ell}{\partial z} = \frac{|y -z|}{y -z}\,.
   \end{align}

#+REVEAL: split
En el contexto de clasificación podemos utilizar:
1. *Devianza binomial*:
   \begin{align}
   \ell(y, z) = -\log(1 + e^{-yz}), \qquad \frac{\partial \ell}{\partial z} = I(y = 1) - h(z)\,.
   \end{align}
2. *Pérdida exponencial*:
   \begin{align}
   \ell(y, z) = e^{-yz}, \qquad \frac{\partial \ell}{\partial z} = - y e^{-yz}\,.
   \end{align}


** Parámetros a optimizar

Los parámetros que usualmente se ajustan con validación cruzada son:
- La tasa de aprendizaje o tamaño de paso $\lambda$.
- El número de términos del modelo $M$.
#+REVEAL: split
Más los adicionales de la familia de árboles:
- Profundidad del árbol.
- Número de observaciones en los nodos terminales.
#+REVEAL: split
Se pueden incorporar adicionales:
- El número de predictores a utilizar (como en ~RF~).
- Alguna cota de reducción de función objetivo para profundizar el árbol.
- Tamaño de submuestreo. 


* Importancia de variables

Tanto para bosques aleatorios como modelos de /boosting/ basados en árboles se puede
estimar cuáles fueron las variables (atributos) que mas contribuyeron en la
construcción del modelo.

#+REVEAL: split
En cada /nodo interno/ de los árboles construidos sabemos que la variable y el punto de corte se
escogieron de acuerdo a que maximizaban la ~mejora~ en dicha región. 

#+REVEAL: split
Para calcular la importancia de la variable $j$ en el  árbol $T$ se suman las
contribuciones cada vez que esta variable fue utilizada para generar cortes
\begin{align}
\mathcal{I}^2_j(T) = \sum_{t = 1}^{J-1}\hat \, \iota^2_t I(v(t) = j)\,,
\end{align}
donde $\hat  \iota^2_t$ es  el registro  de la  mejora en  ~RSS~, ~Gini~  o ~entropía
cruzada~ por el  nodo $t$ cuando este  nodo toma el corte  utilizando la variable
$v(t)$.

#+REVEAL: split
La métrica de importancia en un ensamble de modelos considera promediar la mejora en todo el ensamble
\begin{align}
\mathcal{I}_j^2 = \frac{1}{M} \sum_{m=1}^{M} \mathcal{I}^2_j(T_m)\,.
\end{align}

#+REVEAL: split
Se acostumbra registrar importancias relativas de manera que la variable con
mayor importancia se le asigna un /score/ de 100 puntos y las demás se calculan de
manera proporcional.


bibliographystyle:abbrvnat
bibliography:references.bib


